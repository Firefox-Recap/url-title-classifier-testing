{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch transformers accelerate datasets evaluate numpy pandas jupyter scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import evaluate\n",
        "from datetime import datetime\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    hamming_loss, accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, average_precision_score, jaccard_score\n",
        ")\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [\n",
        "    \"News\", \"Entertainment\", \"Shop\", \"Chat\", \"Education\",\n",
        "    \"Government\", \"Health\", \"Technology\", \"Work\", \"Travel\", \"Uncategorized\"\n",
        "]\n",
        "num_labels = len(labels)\n",
        "id2label = {i: label for i, label in enumerate(labels)}\n",
        "label2id = {label: i for i, label in enumerate(labels)}\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"url-title-classifier\",\n",
        "    name=f\"training-run-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        ")\n",
        "\n",
        "# Model and training parameters\n",
        "MODEL_PATH = \"answerdotai/ModernBERT-base\"\n",
        "LEARNING_RATE = 2e-5\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 3\n",
        "UNFREEZE_START_LAYER = 18 #22 layers\n",
        "\n",
        "# Log config to wandb\n",
        "wandb.config.update({\n",
        "    \"model_name\": MODEL_PATH,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_epochs\": NUM_EPOCHS,\n",
        "    \"num_labels\": num_labels,\n",
        "    \"labels\": labels,\n",
        "    \"unfreeze_start_layer\": UNFREEZE_START_LAYER,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('../data/processed/cleaned_classified_data.parquet')\n",
        "df = df[[df.columns[0], df.columns[1], df.columns[9]]]\n",
        "df.columns = ['url', 'title', 'category']\n",
        "\n",
        "#Create a dataset for training and validation\n",
        "dataset = Dataset.from_pandas(df)\n",
        "split_dataset = dataset.train_test_split(test_size=0.1, seed=1)\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': split_dataset['train'],\n",
        "    'validation': split_dataset['test']\n",
        "})\n",
        "\n",
        "# Log dataset info\n",
        "wandb.config.update({\n",
        "    \"train_size\": len(dataset_dict['train']),\n",
        "    \"val_size\": len(dataset_dict['validation'])\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "# Freeze/unfreeze layers as per your implementation\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "num_layers = 22  # ModernBERT has 22 layers\n",
        "for i in range(num_layers - UNFREEZE_START_LAYER, num_layers):\n",
        "    for param in model.base_model.layers[i].parameters():\n",
        "        param.requires_grad = True\n",
        "for param in model.base_model.final_norm.parameters():\n",
        "    param.requires_grad = True\n",
        "# Log model architecture\n",
        "wandb.watch(model, log=\"all\", log_freq=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "# This needs to be  [CLS][DOMAIN]{domain}[PATH]{path}[TITLE]{title}[SEP]\n",
        "tokenized_data = dataset_dict.map(preprocess_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, true_labels = eval_pred\n",
        "    probabilities = 1 / (1 + np.exp(-logits))\n",
        "    predictions = (probabilities >= 0.5).astype(np.int32)\n",
        "    true_labels_int = true_labels.astype(np.int32)\n",
        "\n",
        "    # Flatten arrays for micro-averaged metrics\n",
        "    predictions_flat = predictions.ravel()\n",
        "    true_labels_flat = true_labels_int.ravel()\n",
        "    probabilities_flat = probabilities.ravel()\n",
        "\n",
        "    metrics = {\n",
        "        \"hamming_loss\": hamming_loss(true_labels_int, predictions),\n",
        "        \"exact_match\": accuracy_score(true_labels_int, predictions),\n",
        "        \n",
        "        # Micro metrics\n",
        "        \"precision_micro\": precision_score(true_labels_flat, predictions_flat, average='micro'),\n",
        "        \"recall_micro\": recall_score(true_labels_flat, predictions_flat, average='micro'),\n",
        "        \"f1_micro\": f1_score(true_labels_flat, predictions_flat, average='micro'),\n",
        "        \n",
        "        # Macro metrics\n",
        "        \"precision_macro\": precision_score(true_labels_int, predictions, average='macro'),\n",
        "        \"recall_macro\": recall_score(true_labels_int, predictions, average='macro'),\n",
        "        \"f1_macro\": f1_score(true_labels_int, predictions, average='macro'),\n",
        "        \n",
        "        # ROC-AUC\n",
        "        \"roc_auc_micro\": roc_auc_score(true_labels_flat, probabilities_flat, average='micro'),\n",
        "        \"roc_auc_macro\": roc_auc_score(true_labels_int, probabilities, average='macro', multi_class='ovr'),\n",
        "    }\n",
        "    \n",
        "    # Per-label metrics\n",
        "    for i, label in enumerate(labels):\n",
        "        metrics[f\"f1_{label}\"] = f1_score(true_labels_int[:, i], predictions[:, i], zero_division=0)\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WandBCustomCallback:\n",
        "    def __init__(self):\n",
        "        self.train_step = 0\n",
        "        self.eval_step = 0\n",
        "        \n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is None:\n",
        "            return\n",
        "            \n",
        "        if \"loss\" in logs:\n",
        "            wandb.log({\n",
        "                \"train/loss\": logs[\"loss\"],\n",
        "                \"train/learning_rate\": logs[\"learning_rate\"],\n",
        "                \"train/epoch\": logs[\"epoch\"],\n",
        "                \"train/step\": self.train_step\n",
        "            })\n",
        "            self.train_step += 1\n",
        "            \n",
        "        if \"eval_loss\" in logs:\n",
        "            metrics_dict = {f\"eval/{k}\": v for k, v in logs.items() if k.startswith(\"eval_\")}\n",
        "            wandb.log(metrics_dict)\n",
        "            self.eval_step += 1\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"data/models/URL-TITLE-classifier\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"wandb\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[WandBCustomCallback()],\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision('high')\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, label in enumerate(labels):\n",
        "    true_labels = np.array([example[\"labels\"][i] for example in tokenized_data[\"validation\"]])\n",
        "    predictions = np.array([pred[i] for pred in trainer.predict(tokenized_data[\"validation\"]).predictions])\n",
        "    predictions = (predictions >= 0.5).astype(int)\n",
        "    \n",
        "    cm = wandb.plot.confusion_matrix(\n",
        "        y_true=true_labels,\n",
        "        preds=predictions,\n",
        "        class_names=[\"Negative\", \"Positive\"],\n",
        "        title=f\"Confusion Matrix - {label}\"\n",
        "    )\n",
        "    wandb.log({f\"confusion_matrix_{label}\": cm})\n",
        "    \n",
        "example_batch = tokenized_data[\"validation\"][:5]\n",
        "predictions = trainer.predict(example_batch).predictions\n",
        "for i, example in enumerate(example_batch):\n",
        "    pred_probs = 1 / (1 + np.exp(-predictions[i]))\n",
        "    pred_labels = (pred_probs >= 0.5).astype(int)\n",
        "    \n",
        "    wandb.log({\n",
        "        f\"example_{i}/url\": example[\"url\"],\n",
        "        f\"example_{i}/title\": example[\"title\"],\n",
        "        f\"example_{i}/true_labels\": example[\"labels\"],\n",
        "        f\"example_{i}/predicted_labels\": pred_labels.tolist(),\n",
        "        f\"example_{i}/prediction_probabilities\": pred_probs.tolist()\n",
        "    })\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model()\n",
        "wandb.save(\"data/models/URL-TITLE-classifier/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
