{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic Data Cleaning \n",
        "\n",
        "This notebook cleans the synthetic data, adds URL and title lengths, and extracts additional features from the URL and title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: bs4 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/taimur/Library/Mobile Documents/com~apple~CloudDocs/Projects/url-title-classifer/url-title-classifier-testing/.venv/lib/python3.13/site-packages (from beautifulsoup4->bs4) (4.13.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "Load the parquet file and drop unnecessary columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet('../data/raw/classified_data.parquet')  # Synthetic data with labels\n",
        "df = df.drop(columns=['content_type', 'server'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Category Labels\n",
        "\n",
        "Clean the `category` column by removing redundant labels and handling the 'Uncategorized' case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_labels(labels_str):\n",
        "    if isinstance(labels_str, str):\n",
        "        labels = [label.strip() for label in labels_str.split(',')]\n",
        "    else:\n",
        "        labels = labels_str\n",
        "    \n",
        "    if \"Uncategorized\" in labels:\n",
        "        cleaned = [label for label in labels if label != \"Uncategorized\"]\n",
        "        return cleaned if len(cleaned) > 0 else [\"Uncategorized\"]\n",
        "    else:\n",
        "        return labels\n",
        "\n",
        "df[\"category\"] = df[\"category\"].apply(clean_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Overview\n",
        "\n",
        "Display the first few rows and summary statistics of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 url  \\\n",
            "0  http://01088888317.com/bbs/board.php?bo_table=...   \n",
            "1                http://3d.jzsc.net/search_3225.html   \n",
            "2           http://22gl.nmjrjx.com/v_info/45979.html   \n",
            "3              http://88yokohama.com/ishidatami.html   \n",
            "4                  http://8p.wanjxx.com/hr/index.php   \n",
            "\n",
            "                                               title  \\\n",
            "0  - 010-8888-8317 29 | -O1O-8888-8317,,,,,,,,,,,...   \n",
            "1                                        ,,,,,su 3d,   \n",
            "2                                                 __   \n",
            "3                                                  U   \n",
            "4                      Office of Human Resources | -   \n",
            "\n",
            "                                             snippet language  \\\n",
            "0  - 010-8888-8317 29 | -O1O-8888-8317,,,,,,,,,,,...       ko   \n",
            "1                                        ,,,,,su 3d,       ko   \n",
            "2  __ : : 0.0 : : : 2022 : 720P/2025-02-12 21:19:...    zh-cn   \n",
            "3  U lqlG Vy[W U U Walking in Okinawa Naha Ishida...       bn   \n",
            "4  Office of Human Resources | - Office of Human ...       en   \n",
            "\n",
            "                                           warc_id             warc_date  \\\n",
            "0  <urn:uuid:95572175-fb41-4767-8d53-21775666b97f>  2025-02-12T21:01:52Z   \n",
            "1  <urn:uuid:39ad2630-2482-4826-9219-51d5d80cc92d>  2025-02-12T19:37:07Z   \n",
            "2  <urn:uuid:631f09c1-2037-46dc-b640-feeb3b435714>  2025-02-12T21:19:13Z   \n",
            "3  <urn:uuid:a944df08-53b5-43ec-a56d-7777d74ab0c4>  2025-02-12T21:16:41Z   \n",
            "4  <urn:uuid:1e63f269-238e-4338-a398-919808ea3d2d>  2025-02-12T19:59:04Z   \n",
            "\n",
            "                                    meta_description  \\\n",
            "0                                        ,,,,,,,,,,,   \n",
            "1                   su,sketchup_sketchup_su 3d,3dmax   \n",
            "2                                        :,,,,,,,...   \n",
            "3  ^n}AANZXAney[WBes1522N^ijCecAOBDr~lA_AT_JAljlG...   \n",
            "4  The Office of Human Resources is an agile, tru...   \n",
            "\n",
            "                        category  \n",
            "0                [Uncategorized]  \n",
            "1        [Technology, Education]  \n",
            "2                [Uncategorized]  \n",
            "3                       [Travel]  \n",
            "4  [Work, Education, Government]  \n",
            "                                                      url  title  \\\n",
            "count                                               49399  49399   \n",
            "unique                                              49399  35858   \n",
            "top     http://01088888317.com/bbs/board.php?bo_table=...          \n",
            "freq                                                    1   1943   \n",
            "\n",
            "                                                  snippet language  \\\n",
            "count                                               49399    49399   \n",
            "unique                                              45649       55   \n",
            "top     One moment, please... Loader Please wait while...       en   \n",
            "freq                                                  132    19005   \n",
            "\n",
            "                                                warc_id             warc_date  \\\n",
            "count                                             49399                 49399   \n",
            "unique                                            49399                 46778   \n",
            "top     <urn:uuid:95572175-fb41-4767-8d53-21775666b97f>  2025-02-12T23:25:34Z   \n",
            "freq                                                  1                     5   \n",
            "\n",
            "       meta_description         category  \n",
            "count             49399            49399  \n",
            "unique            18750              573  \n",
            "top                      [Uncategorized]  \n",
            "freq              27084             8885  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop Missing Values and Duplicates\n",
        "\n",
        "Remove rows with missing values and duplicate entries based on key columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['url', 'title', 'snippet', 'language', 'warc_id', 'meta_description', 'category'])\n",
        "df = df.drop_duplicates(subset=['url'], keep='first')\n",
        "df = df.drop_duplicates(subset=['warc_id'], keep='first')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Text Fields\n",
        "\n",
        "Ensure that text fields are of string type for consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.astype({\n",
        "    'url': 'string',\n",
        "    'title': 'string',\n",
        "    'snippet': 'string',\n",
        "    'language': 'string',\n",
        "    'warc_id': 'string',\n",
        "    'meta_description': 'string'\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering: URL and Title Lengths\n",
        "\n",
        "Add new columns that capture the length of the URL and the title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 url  \\\n",
            "0  http://01088888317.com/bbs/board.php?bo_table=...   \n",
            "1                http://3d.jzsc.net/search_3225.html   \n",
            "2           http://22gl.nmjrjx.com/v_info/45979.html   \n",
            "3              http://88yokohama.com/ishidatami.html   \n",
            "4                  http://8p.wanjxx.com/hr/index.php   \n",
            "\n",
            "                                               title  url_length  title_length  \n",
            "0  - 010-8888-8317 29 | -O1O-8888-8317,,,,,,,,,,,...         103            61  \n",
            "1                                        ,,,,,su 3d,          35            11  \n",
            "2                                                 __          40             2  \n",
            "3                                                  U          37             1  \n",
            "4                      Office of Human Resources | -          33            29  \n"
          ]
        }
      ],
      "source": [
        "df['url_length'] = df['url'].str.len()\n",
        "df['title_length'] = df['title'].str.len()\n",
        "\n",
        "print(df[['url', 'title', 'url_length', 'title_length']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional URL Feature Extraction\n",
        "\n",
        "Extract features from the URL such as domain, path depth, query count, digit count, and special character count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_url_features(url):\n",
        "    parsed = urlparse(url)\n",
        "    domain = parsed.netloc\n",
        "    path = parsed.path\n",
        "    query = parsed.query\n",
        "    \n",
        "    # Count the number of non-empty segments in the path\n",
        "    path_depth = len([seg for seg in path.split('/') if seg])\n",
        "    \n",
        "    # Count query parameters if any exist\n",
        "    query_count = len(query.split('&')) if query else 0\n",
        "    \n",
        "    # Count digits and special characters in the URL\n",
        "    digit_count = sum(c.isdigit() for c in url)\n",
        "    special_char_count = sum(c in string.punctuation for c in url)\n",
        "    \n",
        "    return pd.Series({\n",
        "        'domain': domain,\n",
        "        'path_depth': path_depth,\n",
        "        'query_count': query_count,\n",
        "        'url_digit_count': digit_count,\n",
        "        'url_special_count': special_char_count\n",
        "    })\n",
        "\n",
        "# Apply URL feature extraction\n",
        "df = df.join(df['url'].apply(extract_url_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Title Feature Extraction\n",
        "\n",
        "Extract features from the title such as word count, average word length, punctuation count, and digit count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_title_features(title):\n",
        "    words = title.split()\n",
        "    word_count = len(words)\n",
        "    avg_word_len = sum(len(word) for word in words) / word_count if word_count > 0 else 0\n",
        "    punctuation_count = sum(c in string.punctuation for c in title)\n",
        "    digit_count = sum(c.isdigit() for c in title)\n",
        "    \n",
        "    return pd.Series({\n",
        "        'title_word_count': word_count,\n",
        "        'title_avg_word_len': avg_word_len,\n",
        "        'title_punctuation_count': punctuation_count,\n",
        "        'title_digit_count': digit_count\n",
        "    })\n",
        "\n",
        "# Apply Title feature extraction\n",
        "df = df.join(df['title'].apply(extract_title_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Overview\n",
        "\n",
        "Display selected columns to verify the extracted features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 url           domain  \\\n",
            "0  http://01088888317.com/bbs/board.php?bo_table=...  01088888317.com   \n",
            "1                http://3d.jzsc.net/search_3225.html      3d.jzsc.net   \n",
            "2           http://22gl.nmjrjx.com/v_info/45979.html  22gl.nmjrjx.com   \n",
            "3              http://88yokohama.com/ishidatami.html   88yokohama.com   \n",
            "4                  http://8p.wanjxx.com/hr/index.php    8p.wanjxx.com   \n",
            "\n",
            "   path_depth  query_count  url_digit_count  url_special_count  \\\n",
            "0           2            8               13                 25   \n",
            "1           1            0                5                  8   \n",
            "2           2            0                7                  9   \n",
            "3           1            0                2                  6   \n",
            "4           2            0                1                  8   \n",
            "\n",
            "                                               title  title_word_count  \\\n",
            "0  - 010-8888-8317 29 | -O1O-8888-8317,,,,,,,,,,,...               5.0   \n",
            "1                                        ,,,,,su 3d,               2.0   \n",
            "2                                                 __               1.0   \n",
            "3                                                  U               1.0   \n",
            "4                      Office of Human Resources | -               6.0   \n",
            "\n",
            "   title_avg_word_len  title_punctuation_count  title_digit_count  \n",
            "0                11.4                     33.0               22.0  \n",
            "1                 5.0                      6.0                1.0  \n",
            "2                 2.0                      2.0                0.0  \n",
            "3                 1.0                      0.0                0.0  \n",
            "4                 4.0                      2.0                0.0  \n"
          ]
        }
      ],
      "source": [
        "print(df[['url', 'domain', 'path_depth', 'query_count', 'url_digit_count', 'url_special_count',\n",
        "          'title', 'title_word_count', 'title_avg_word_len', 'title_punctuation_count', 'title_digit_count']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Cleaned and Enhanced Data\n",
        "\n",
        "Save the cleaned and feature-enhanced dataframe to a new parquet file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_parquet('../data/processed/cleaned_classified.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
